{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Encontra diretorio atual\n",
    "atual_dir = os.getcwd()\n",
    "\n",
    "# Acessa arquivo pkl das noticias\n",
    "parent_dir = os.path.split(atual_dir)\n",
    "\n",
    "parent_dir = os.path.split(parent_dir[0])\n",
    "\n",
    "caminho_pkl = os.path.join(parent_dir[0], \"Pre-processamento\\\\noticias_pre_processadas_df.pkl\")\n",
    "\n",
    "# Carregar dataframe salvo em formato pickle\n",
    "df = pd.read_pickle(caminho_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar a classe Word2Vec da biblioteca gensim, que permite criar e treinar modelos de incorporação de palavras (word embeddings) usando o algoritmo Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Importar a classe CallbackAny2Vec da biblioteca gensim, que fornece uma base para criar funções de retorno de chamada (callbacks) personalizadas \n",
    "# durante o treinamento de modelos Word2Vec (ou outros modelos baseados em Any2Vec)\n",
    "from gensim.models.callbacks import CallbackAny2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTextCallback(CallbackAny2Vec):\n",
    "    def __init__(self, total_epochs):\n",
    "        self.epoch = 0  # Inicializa o contador de épocas\n",
    "        self.total_epochs = total_epochs  # Armazena o número total de épocas para exibição\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        self.epoch += 1  # Incrementa o contador de épocas\n",
    "        print(f\"Época {self.epoch} de {self.total_epochs}...\") # Imprime uma mensagem informando o número da época atual e o total de épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte a coluna 'Texto' do DataFrame em uma lista e armazena na variável preprocessed_articles, para ser usada no word2vec\n",
    "preprocessed_articles = df['Texto'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1 de 10...\n",
      "Época 2 de 10...\n",
      "Época 3 de 10...\n",
      "Época 4 de 10...\n",
      "Época 5 de 10...\n",
      "Época 6 de 10...\n",
      "Época 7 de 10...\n",
      "Época 8 de 10...\n",
      "Época 9 de 10...\n",
      "Época 10 de 10...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37786900, 38768900)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instancia o modelo Word2Vec com os seguintes parâmetros:\n",
    "# vector_size=100: Dimensão do vetor de palavras gerado\n",
    "# window=5: Tamanho da janela de contexto ao redor de cada palavra\n",
    "# min_count=1: Ignora palavras com frequência total menor que 1\n",
    "# workers=4: Número de threads a serem usadas para treinar o modelo\n",
    "word2vec_model = Word2Vec(vector_size=100, window=5, min_count=1, workers=4) #Se adicionar sg=0, muda pra CBOW\n",
    "\n",
    "# Constrói o vocabulário com base nos artigos pré-processados\n",
    "word2vec_model.build_vocab(preprocessed_articles)\n",
    "\n",
    "# Define o número total de épocas para o treinamento do modelo\n",
    "total_epochs = 10\n",
    "\n",
    "# Instancia o callback que exibe o progresso do treinamento após cada época\n",
    "callback = SimpleTextCallback(total_epochs)\n",
    "\n",
    "# Treina o modelo Word2Vec nos artigos pré-processados, utilizando o número total de exemplos e épocas definidos\n",
    "word2vec_model.train(preprocessed_articles, total_examples=word2vec_model.corpus_count, \n",
    "                     epochs=total_epochs, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o modelo Word2Vec para um arquivo\n",
    "word2vec_model.save(\"modelo_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('governar', 0.6413506269454956),\n",
       " ('Governo', 0.5855116248130798),\n",
       " ('gestoes', 0.5408600568771362),\n",
       " ('aliado', 0.5138075351715088),\n",
       " ('gestao', 0.5079231262207031),\n",
       " ('economica', 0.500443696975708),\n",
       " ('intervencao', 0.4713590741157532),\n",
       " ('governante', 0.44843995571136475),\n",
       " ('estado', 0.4446102976799011),\n",
       " ('enconstar', 0.44430816173553467)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encontra palavras mais similares de acordo com a palavra alvo\n",
    "word2vec_model.wv.most_similar('governo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria dois dicionários para mapear as palavras aos seus respectivos índices e vice-versa.\n",
    "# Isso é feito para facilitar a conversão entre palavras e índices durante a criação de sequências\n",
    "# numéricas que representam os textos. Essas sequências numéricas serão usadas como entrada para\n",
    "# modelos de aprendizado de máquina, como redes neurais.\n",
    "# Exemplo: \n",
    "# Suponha que o vocabulário seja ['casa', 'carro', 'jardim'], então os dicionários serão:\n",
    "# word_to_index = {'casa': 1, 'carro': 2, 'jardim': 3}\n",
    "# index_to_word = {1: 'casa', 2: 'carro', 3: 'jardim'}\n",
    "\n",
    "# 'word_to_index' é um dicionário que mapeia cada palavra ao seu índice correspondente.\n",
    "word_to_index = {}\n",
    "\n",
    "# 'index_to_word' é um dicionário que mapeia cada índice à palavra correspondente.\n",
    "index_to_word = {}\n",
    "\n",
    "# Itera sobre a lista de palavras únicas obtida do modelo Word2Vec\n",
    "for i, word in enumerate(word2vec_model.wv.index_to_key):\n",
    "    # Atribui a palavra ao índice i + 1 no dicionário 'word_to_index'.\n",
    "    # Os índices começam em 1 para reservar o índice 0 para preenchimento (padding) quando necessário.\n",
    "    word_to_index[word] = i + 1\n",
    "    \n",
    "    # Atribui o índice i + 1 à palavra no dicionário 'index_to_word'.\n",
    "    index_to_word[i + 1] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvar dicionários em arquivos usando pickle\n",
    "with open('word_to_index.pickle', 'wb') as handle:\n",
    "    pickle.dump(word_to_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('index_to_word.pickle', 'wb') as handle:\n",
    "    pickle.dump(index_to_word, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22284/22284 [00:01<00:00, 20462.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 'sequences' é uma lista que armazenará as sequências numéricas correspondentes aos artigos pré-processados.\n",
    "sequences = []\n",
    "\n",
    "# Itera sobre os artigos pré-processados.\n",
    "for tokens in tqdm(preprocessed_articles):\n",
    "    # 'sequence' é uma lista temporária que armazenará a sequência numérica para o artigo atual.\n",
    "    sequence = []\n",
    "    \n",
    "    # Itera sobre os tokens (palavras) no artigo atual.\n",
    "    for token in tokens:\n",
    "        # Verifica se o token atual está presente no dicionário 'word_to_index'.\n",
    "        if token in word_to_index:\n",
    "            # Se o token estiver presente, adiciona o índice correspondente à lista 'sequence'.\n",
    "            sequence.append(word_to_index[token])\n",
    "    \n",
    "    # Após processar todos os tokens do artigo atual, adiciona a sequência numérica completa à lista 'sequences'.\n",
    "    sequences.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvar a lista 'sequences' em um arquivo usando pickle\n",
    "with open('sequences.pickle', 'wb') as handle:\n",
    "    pickle.dump(sequences, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poder decidir expulsar deputado federal Carlos gaguim partido Apos policia federal busca apreensoes gabinete de ele Camara legenda abrir espaco receber senadora expulsar pmdb katia abreu nota legenda informar afastamento parlamentar ja acordar filiado sigla “ parlamentar ter comunicar conclusao desfiliacao semana fato noticiar hoje executiva nacional poder solicitar imediato cancelamento filiacao quadro partido ” partido passado chegar cogitar lancar parlamentar candidato senado “ investigacao amplo apuracao eventual crime cometir consequente responsabilizacao envolvido ser puner maximo rigor lei independentemente posicao cargo ocupar ”\n"
     ]
    }
   ],
   "source": [
    "# Utiliza uma compreensão de lista para converter a sequência numérica do primeiro artigo em uma lista de palavras.\n",
    "# Para cada índice 'i' na sequência numérica 'sequences[0]', obtém a palavra correspondente no dicionário 'index_to_word'.\n",
    "# A compreensão de lista retorna uma lista de palavras.\n",
    "word_list = [index_to_word[i] for i in sequences[0]]\n",
    "\n",
    "# Usa o método 'join()' para combinar as palavras da lista 'word_list' em uma única string.\n",
    "# As palavras são separadas por um espaço em branco.\n",
    "text = \" \".join(word_list)\n",
    "\n",
    "# Imprime o texto reconstruído a partir da sequência numérica.\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
